{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSHlAbqzDFDq"
      },
      "source": [
        "# Preparing Data for finetuning Llama 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ygm5bK6mdy"
      },
      "source": [
        "### Installing and Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers==4.41.2 datasets==2.19.2"
      ],
      "metadata": {
        "id": "cfthJmYWZQrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XlC7RC_iY-UR",
        "outputId": "5f8a2649-995f-4fc1-eaea-151c7648c286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.41.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "datasets.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BZzb4RmJZGdR",
        "outputId": "cb42451d-d37c-49ce-f6de-7f7c1d1c5401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.19.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSlw3SjSRL93",
        "outputId": "a5a9ea0f-30cc-4025-c619-8c012017b261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "7cZhrSYXW1p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzfEbaT_6zRx"
      },
      "source": [
        "### Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwCYNwKaYUxn"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Fine tuning Llama/Laptops_Train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Fine tuning Llama/Laptops_Test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Dataset"
      ],
      "metadata": {
        "id": "knn_MZI_xKRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast"
      ],
      "metadata": {
        "id": "owf0Tr1TyCCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing Test set\n",
        "test_final_prompts = []\n",
        "for raw_text, aspect in zip(test_df['raw_text'], test_df['aspectTerms']):\n",
        "    user_dict = {\"role\":\"user\"}\n",
        "    assistant_dict = {\"role\":\"assistant\"}\n",
        "    defination = 'Identify the aspects (both implicit and explicit) and the aspects sentiment polarity only. In cases where there are no aspects the output should be noaspectterm:none.'\n",
        "    example1 = 'Positive example -\\ninput: I charge it at night and skip taking the cord with me because of the good battery life.\\noutput: battery life:positive, '\n",
        "    example2 = 'Neutral example -\\ninput: Nightly my computer defrags itself and runs a virus scan.\\noutput: virus scan:neutral'\n",
        "    instruct = 'Now complete the following example-\\ninput:'\n",
        "\n",
        "    user_content = f'{defination}\\n{example1}\\n{example2}\\n{instruct}{raw_text}'\n",
        "\n",
        "    user_dict.update({\"content\":user_content})\n",
        "\n",
        "    aspect = ast.literal_eval(aspect)\n",
        "\n",
        "    s = ''\n",
        "\n",
        "    for i,j in enumerate(aspect):\n",
        "        if i == len(aspect)-1:\n",
        "            s =  s +  j['term'] + ':' + j['polarity']\n",
        "        else:\n",
        "            s = s+ j['term'] + ':' + j['polarity']+', '\n",
        "\n",
        "    assistant_content = f'output: {s}'\n",
        "    assistant_dict.update({\"content\":assistant_content})\n",
        "\n",
        "    test_final_prompts.append([user_dict, assistant_dict])"
      ],
      "metadata": {
        "id": "4GStdZQDxW46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_final_prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvpgTqWqX52o",
        "outputId": "6d9e290f-c43c-4942-f862-378e641abbdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'Identify the aspects (both implicit and explicit) and the aspects sentiment polarity only. In cases where there are no aspects the output should be noaspectterm:none.\\nPositive example -\\ninput: I charge it at night and skip taking the cord with me because of the good battery life.\\noutput: battery life:positive, \\nNeutral example -\\ninput: Nightly my computer defrags itself and runs a virus scan.\\noutput: virus scan:neutral\\nNow complete the following example-\\ninput:Boot time is super fast, around anywhere from 35 seconds to 1 minute.'}, {'role': 'assistant', 'content': 'output: Boot time:positive'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing Train set\n",
        "train_final_prompts = []\n",
        "for raw_text, aspect in zip(train_df['raw_text'], train_df['aspectTerms']):\n",
        "    user_dict = {\"role\":\"user\"}\n",
        "    assistant_dict = {\"role\":\"assistant\"}\n",
        "    defination = 'Identify the aspects (both implicit and explicit) and the aspects sentiment polarity only. In cases where there are no aspects the output should be noaspectterm:none.'\n",
        "    example1 = 'Positive example -\\ninput: I charge it at night and skip taking the cord with me because of the good battery life.\\noutput: battery life:positive, '\n",
        "    example2 = 'Neutral example -\\ninput: Nightly my computer defrags itself and runs a virus scan.\\noutput: virus scan:neutral'\n",
        "    instruct = 'Now complete the following example-\\ninput:'\n",
        "\n",
        "    user_content = f'{defination}\\n{example1}\\n{example2}\\n{instruct}{raw_text}'\n",
        "\n",
        "    user_dict.update({\"content\":user_content})\n",
        "\n",
        "    aspect = ast.literal_eval(aspect)\n",
        "\n",
        "    s = ''\n",
        "\n",
        "    for i,j in enumerate(aspect):\n",
        "        if i == len(aspect)-1:\n",
        "            s =  s +  j['term'] + ':' + j['polarity']\n",
        "        else:\n",
        "            s = s+ j['term'] + ':' + j['polarity']+', '\n",
        "\n",
        "    assistant_content = f'output: {s}'\n",
        "    assistant_dict.update({\"content\":assistant_content})\n",
        "\n",
        "    train_final_prompts.append([user_dict, assistant_dict])"
      ],
      "metadata": {
        "id": "rVCCVIV4yEk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_final_prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnONi-YeYHTb",
        "outputId": "bb7a78f5-eb4d-442c-8b24-c6fec629890a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'Identify the aspects (both implicit and explicit) and the aspects sentiment polarity only. In cases where there are no aspects the output should be noaspectterm:none.\\nPositive example -\\ninput: I charge it at night and skip taking the cord with me because of the good battery life.\\noutput: battery life:positive, \\nNeutral example -\\ninput: Nightly my computer defrags itself and runs a virus scan.\\noutput: virus scan:neutral\\nNow complete the following example-\\ninput:I charge it at night and skip taking the cord with me because of the good battery life.'}, {'role': 'assistant', 'content': 'output: cord:neutral, battery life:positive'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-chat-hf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcYjsLE7yal5",
        "outputId": "135734d2-8bd5-44c4-8405-12499dca448f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [tokenizer.apply_chat_template(i, tokenize=False, add_generation_prompt=False) for i in train_final_prompts]"
      ],
      "metadata": {
        "id": "yqkZeirS71Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "treZ_wsYYhsM",
        "outputId": "b7504de1-716c-475c-bb90-56699f38961e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Identify the aspects (both implicit and explicit) and the aspects sentiment polarity only. In cases where there are no aspects the output should be noaspectterm:none.\n",
            "Positive example -\n",
            "input: I charge it at night and skip taking the cord with me because of the good battery life.\n",
            "output: battery life:positive, \n",
            "Neutral example -\n",
            "input: Nightly my computer defrags itself and runs a virus scan.\n",
            "output: virus scan:neutral\n",
            "Now complete the following example-\n",
            "input:I charge it at night and skip taking the cord with me because of the good battery life. [/INST] output: cord:neutral, battery life:positive </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = [tokenizer.apply_chat_template(i, tokenize=False, add_generation_prompt=False) for i in test_final_prompts]"
      ],
      "metadata": {
        "id": "pS5plyxR8WXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFoUBxZSYpiN",
        "outputId": "503f56ee-7f0c-4d5d-a5ba-3ccc22c6630c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Identify the aspects (both implicit and explicit) and the aspects sentiment polarity only. In cases where there are no aspects the output should be noaspectterm:none.\n",
            "Positive example -\n",
            "input: I charge it at night and skip taking the cord with me because of the good battery life.\n",
            "output: battery life:positive, \n",
            "Neutral example -\n",
            "input: Nightly my computer defrags itself and runs a virus scan.\n",
            "output: virus scan:neutral\n",
            "Now complete the following example-\n",
            "input:Boot time is super fast, around anywhere from 35 seconds to 1 minute. [/INST] output: Boot time:positive </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvRmwTUH8K6x",
        "outputId": "415c3fbe-fe2b-4936-9b19-b4f737855555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3045, 800)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(train_data).to_csv('/content/drive/MyDrive/Fine tuning Llama/train_prompts.csv')\n",
        "pd.DataFrame(test_data).to_csv('/content/drive/MyDrive/Fine tuning Llama/test_prompts.csv')"
      ],
      "metadata": {
        "id": "Ew6Il8IG8fSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}